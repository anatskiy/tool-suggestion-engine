{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "from bioblend.galaxy import GalaxyInstance\n",
    "from bioblend.galaxy.histories import HistoryClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u/abc/galaxy\n"
     ]
    }
   ],
   "source": [
    "cd ../galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./config/galaxy.ini') as file:\n",
    "    # default\n",
    "    db_path = 'database/universe.sqlite'\n",
    "\n",
    "    # if different value in config file\n",
    "    for line in file:\n",
    "        if re.match('^database_connection\\ =.*', line):\n",
    "            db_path = re.sub('database_connection\\ = sqlite:///./', '', line)\n",
    "            # without the index the string finishes with a space\n",
    "            db_path = re.sub('\\?.*', '', db_path)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key = open('../galaxy_api_key').read()\n",
    "galaxy_url = 'http://localhost:8080'\n",
    "gi = GalaxyInstance(galaxy_url, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative: load workflows from local files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "local_workflow_folder = '../tool-suggestion-engine/shared-workflows'\n",
    "list_of_wo = !ls $local_workflow_folder/*.ga"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for file in list_of_wo:\n",
    "    gi.workflows.import_workflow_from_local_path(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## alternative: load histories from files and convert histories to workflows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "hi = HistoryClient(gi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download histories to a binary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for id in [item['id'] for item in hi.get_histories()]:\n",
    "    hi.download_history(id, hi.export_history(id), open(str(id) + '.history', 'w'), chunk_size=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "upload binary history to database\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print \"not supported by the API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clear workflow table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for w in gi.workflows.get_workflows():\n",
    "    gi.workflows.delete_workflow(w['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display existing workflows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!scripts/api/./display.py $(cat ../galaxy_api_key) http://localhost:8080/api/workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative: upload histories and workflows downloaded with SQL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "histo_read = pd.read_csv('histories.csv')\n",
    "w_steps_read = pd.read_csv('workflow_steps.csv')\n",
    "w_steps_connexion_read = pd.read_csv('workflow_steps_connexions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACHTUNG: the following _update_ query may break the versionning of the database**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "histo_read.to_sql('history', con=conn, if_exists='replace')\n",
    "w_steps_read.to_sql('workflow_steps', con=conn, if_exists='replace')\n",
    "w_steps_connexion_read.to_sql('workflow_steps_connexions', con=conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract workflows from histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display existing histories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!scripts/api/./display.py $(cat ../galaxy_api_key) http://localhost:8080/api/histories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def extract_workflow_from_history(wid):\n",
    "    payload = \"{'from_history_id': '\" + wid + \"', 'workflow_name': '\" + wid + \"'}\"\n",
    "    key = !cat ../galaxy_api_key\n",
    "    print key[0]\n",
    "    print requests.post(\"http://localhost:8080/api/workflows?key=\" + str(key[0]),\n",
    "                         headers={'Content-Type': 'application/json'}, data=payload).content\n",
    "    \n",
    "    #os.system(\"curl  http://localhost:8080/api/workflows?key=$(cat ../galaxy_api_key) \\\n",
    "   # -H 'Content-Type: application/json' --data \\\"\" + payload + \"\\\"\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attempt to pass a string variable to the curl command in os.system fails (too many levels of \\\").\n",
    "\n",
    "The following function stores the _payload_ in a file before passing the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_workflow_from_history(wid):\n",
    "    payload = \"{\\\"from_history_id\\\": \\\"\" + wid + \"\\\",  \\\"workflow_name\\\": \\\"\" + \"extracted-\" +  wid + \"\\\"}\"\n",
    "    open('payload.json', 'w').write(payload)\n",
    "    !curl http://localhost:8080/api/workflows?key=$(cat ../galaxy_api_key) -H \"Content-Type: application/json\"\\\n",
    "    --data @payload.json\n",
    "    !rm -f payload.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract history and display the extracted history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"extracted-1cd8e2f6b131e891\", \"tags\": [], \"deleted\": false, \"latest_workflow_uuid\": \"068cd09c-a58c-4cf4-8fe0-2543d3f6cf58\", \"url\": \"/api/workflows/c385e49b9fe1853c\", \"published\": false, \"model_class\": \"StoredWorkflow\", \"id\": \"c385e49b9fe1853c\"}\n",
      "{\"name\": \"extracted-f597429621d6eb2b\", \"tags\": [], \"deleted\": false, \"latest_workflow_uuid\": \"324393fb-e4fb-4053-820b-6f0cedabfb5f\", \"url\": \"/api/workflows/f7bb1edd6b95db62\", \"published\": false, \"model_class\": \"StoredWorkflow\", \"id\": \"f7bb1edd6b95db62\"}\n"
     ]
    }
   ],
   "source": [
    "for item in gi.histories.get_histories():\n",
    "    extract_workflow_from_history(item['id'])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display uploaded workflows and extracted workflows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "!scripts/api/./display.py $(cat ../galaxy_api_key) http://localhost:8080/api/workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get connections\n",
    "\n",
    "1. get connections (by id of workflow steps)\n",
    "2. get tool id corresponding to each workflow step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   workflow_id  out_port  in_port\n",
      "0           28         1        3\n"
     ]
    }
   ],
   "source": [
    "get_associations_query = '''\n",
    "SELECT distinct w_s.workflow_id, w_s.id AS out_port, w_c.input_step_id AS in_port\n",
    "FROM workflow_step AS w_s, workflow_step_connection AS w_c\n",
    "WHERE w_s.id=w_c.output_step_id\n",
    "'''\n",
    "assoc = pd.read_sql(get_associations_query, con=conn)\n",
    "\n",
    "print assoc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id tool_id\n",
      "0   1    None\n",
      "1   2    None\n",
      "2   3    cat1\n"
     ]
    }
   ],
   "source": [
    "get_tool_id_query = '''\n",
    "SELECT distinct w_s.id, w_s.tool_id\n",
    "FROM workflow_step AS w_s\n",
    "'''\n",
    "\n",
    "step_tool = pd.read_sql(get_tool_id_query, con=conn)\n",
    "print step_tool[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace degenerated step id by unique tool id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  out_port_tool in_port_tool  workflow_id  out_port  in_port\n",
      "0          None         cat1           28         1        3\n"
     ]
    }
   ],
   "source": [
    "out_tool_ids = [step_tool.tool_id[step_tool.id == item].values[0] for index, item in enumerate(assoc.out_port)]\n",
    "in_tool_ids = [step_tool.tool_id[step_tool.id == item].values[0] for index, item in enumerate(assoc.in_port)]\n",
    "\n",
    "assoc.insert(0, 'out_port_tool', pd.DataFrame(out_tool_ids))\n",
    "assoc.insert(1, 'in_port_tool', pd.DataFrame(in_tool_ids))\n",
    "print assoc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## association rule identification\n",
    "\n",
    "dictionnary with tool as key and tool connected as output as values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for item in assoc.out_port_tool.unique():\n",
    "    d[item] = [{}]\n",
    "\n",
    "for index, tool in enumerate(assoc.out_port_tool):\n",
    "    #print index, tool, assoc.in_port_tool[index]\n",
    "    if assoc.in_port_tool[index] not in d[tool][0].keys():\n",
    "        d[tool][0][assoc.in_port_tool[index]] = 1\n",
    "    else:\n",
    "        d[tool][0][assoc.in_port_tool[index]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort associations by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recomm = {'tool': [], 'suggestion': [], 'proof': []}\n",
    "\n",
    "for tool in d.keys():\n",
    "    #d[tool].sort(key=lambda x: x[1])çç\n",
    "    \n",
    "    tool_max = max(d[None][0], key=d[None][0].get)\n",
    "    \n",
    "    recomm['tool'].append(tool)\n",
    "    recomm['suggestion'].append(tool_max)\n",
    "    recomm['proof'].append( sorted(d[tool][0].values())[-1]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendation = pd.DataFrame(recomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:939: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['suggestion', 'tool']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "recommendation.to_hdf('recommendation_table.hdf', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see [use-suggestions.ipynb](use-suggestions.ipynb) and [use-suggestions.py](use-suggestions.py)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
